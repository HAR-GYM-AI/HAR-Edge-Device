{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b8b3370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "     SESSION-LEVEL REP PREDICTION PIPELINE (REGRESSION)\n",
      "======================================================================\n",
      "\n",
      "[1/3] Loading and processing raw data...\n",
      "✓ Loaded 75 sessions.\n",
      "\n",
      "[2/3] Aggregating window features to the session level...\n",
      "✓ Created a session-level dataset with 63 sessions and 282 features.\n",
      "\n",
      "[3/3] Training and evaluating the session-level regression model...\n",
      "Data split: 47 training sessions, 16 test sessions.\n",
      "\n",
      "======================================================================\n",
      "         SESSION-LEVEL REGRESSION MODEL PERFORMANCE\n",
      "======================================================================\n",
      "--- Key Performance Metrics ---\n",
      "Mean Absolute Error (MAE): 2.38 reps\n",
      "  -> Interpretation: On average, the model's prediction was off by ~2.38 reps.\n",
      "Root Mean Squared Error (RMSE): 2.57 reps\n",
      "  -> Interpretation: Similar to MAE, but penalizes large errors more heavily.\n",
      "R-squared (R²): 0.30\n",
      "  -> Interpretation: The model explains 30% of the variance in the session rep counts.\n",
      "\n",
      "--- Repetition Volume Analysis ---\n",
      "Total True Reps in Test Set:      78\n",
      "Total Predicted Reps in Test Set: 70\n",
      "-> Model predicted 89.74% of the actual rep volume.\n",
      "\n",
      "--- Example Predictions (Predicted vs. True) ---\n",
      "    True Reps  Predicted Reps\n",
      "61          5               3\n",
      "57          2               5\n",
      "0           5               4\n",
      "43          1               4\n",
      "5           5               2\n",
      "36          7               5\n",
      "16          3               6\n",
      "12          2               4\n",
      "25          5               3\n",
      "60          9               5\n",
      "======================================================================\n",
      "\n",
      "✓ Session-level regression model and features saved successfully.\n",
      "\n",
      "Pipeline finished.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def create_session_level_features(filepath='mongodb_export_cleaned.json'):\n",
    "    \"\"\"\n",
    "    Loads raw data and aggregates window-level features up to the session level,\n",
    "    creating a feature set where each row represents one full session.\n",
    "    \"\"\"\n",
    "    print(\"\\n[1/3] Loading and processing raw data...\")\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "    except json.JSONDecodeError:\n",
    "        data = [json.loads(line) for line in open(filepath, 'r', encoding='utf-8') if line.strip()]\n",
    "    print(f\"✓ Loaded {len(data)} sessions.\")\n",
    "\n",
    "    print(\"\\n[2/3] Aggregating window features to the session level...\")\n",
    "    aggregated_sessions = []\n",
    "    for session in data:\n",
    "        metadata = session.get('session_metadata', {})\n",
    "        target_reps = metadata.get('target_reps')\n",
    "        session_id = session.get('_id')\n",
    "\n",
    "        if target_reps is None:\n",
    "            continue\n",
    "\n",
    "        windows = [\n",
    "            w['features'] for w in session.get('sorted_windows', [])\n",
    "            if w.get('window_type') == 'long' and 'features' in w\n",
    "        ]\n",
    "\n",
    "        if not windows:\n",
    "            continue\n",
    "            \n",
    "        df_windows = pd.DataFrame(windows)\n",
    "        \n",
    "        # --- **THE FIX**: Select only numeric columns before aggregation ---\n",
    "        # This prevents the error by ignoring columns like timestamps.\n",
    "        df_numeric_windows = df_windows.select_dtypes(include=np.number)\n",
    "        \n",
    "        if df_numeric_windows.empty:\n",
    "            continue\n",
    "\n",
    "        aggregations = ['mean', 'std', 'min', 'max', 'median']\n",
    "        df_agg = df_numeric_windows.agg(aggregations)\n",
    "        \n",
    "        df_flat = df_agg.unstack().to_frame().T\n",
    "        df_flat.columns = [f'{i}_{j}' for i, j in df_flat.columns]\n",
    "        \n",
    "        df_flat['session_id'] = session_id\n",
    "        df_flat['target_reps'] = target_reps\n",
    "        \n",
    "        aggregated_sessions.append(df_flat)\n",
    "\n",
    "    if not aggregated_sessions:\n",
    "        raise ValueError(\"No valid sessions with features and target reps were found.\")\n",
    "\n",
    "    df_sessions_agg = pd.concat(aggregated_sessions).reset_index(drop=True).fillna(0)\n",
    "    print(f\"✓ Created a session-level dataset with {len(df_sessions_agg)} sessions and {len(df_sessions_agg.columns)} features.\")\n",
    "    return df_sessions_agg\n",
    "\n",
    "def train_evaluate_session_model(df_sessions):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a regression model to predict total session reps.\n",
    "    \"\"\"\n",
    "    print(\"\\n[3/3] Training and evaluating the session-level regression model...\")\n",
    "\n",
    "    y = df_sessions['target_reps']\n",
    "    X = df_sessions.drop(columns=['session_id', 'target_reps'])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Data split: {len(X_train)} training sessions, {len(X_test)} test sessions.\")\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=500,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        early_stopping_rounds=20\n",
    "    )\n",
    "    \n",
    "    eval_set = [(X_test, y_test)]\n",
    "    model.fit(X_train, y_train, eval_set=eval_set, verbose=False)\n",
    "\n",
    "    y_pred_float = model.predict(X_test)\n",
    "    y_pred_int = np.round(y_pred_float).astype(int)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred_int)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_int))\n",
    "    r2 = r2_score(y_test, y_pred_float)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"         SESSION-LEVEL REGRESSION MODEL PERFORMANCE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"--- Key Performance Metrics ---\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f} reps\")\n",
    "    print(\"  -> Interpretation: On average, the model's prediction was off by ~{:.2f} reps.\".format(mae))\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f} reps\")\n",
    "    print(\"  -> Interpretation: Similar to MAE, but penalizes large errors more heavily.\")\n",
    "    print(f\"R-squared (R²): {r2:.2f}\")\n",
    "    print(\"  -> Interpretation: The model explains {:.0f}% of the variance in the session rep counts.\".format(r2 * 100))\n",
    "\n",
    "    print(\"\\n--- Repetition Volume Analysis ---\")\n",
    "    total_true_reps = y_test.sum()\n",
    "    total_predicted_reps = y_pred_int.sum()\n",
    "    print(f\"Total True Reps in Test Set:      {total_true_reps}\")\n",
    "    print(f\"Total Predicted Reps in Test Set: {total_predicted_reps}\")\n",
    "    if total_true_reps > 0:\n",
    "        print(f\"-> Model predicted {(total_predicted_reps / total_true_reps) * 100:.2f}% of the actual rep volume.\")\n",
    "        \n",
    "    print(\"\\n--- Example Predictions (Predicted vs. True) ---\")\n",
    "    df_results = pd.DataFrame({'True Reps': y_test, 'Predicted Reps': y_pred_int})\n",
    "    print(df_results.head(10))\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    joblib.dump(model, 'session_reps_model.joblib')\n",
    "    joblib.dump(X.columns.tolist(), 'session_reps_features.joblib')\n",
    "    print(\"\\n✓ Session-level regression model and features saved successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 70)\n",
    "    print(\"     SESSION-LEVEL REP PREDICTION PIPELINE (REGRESSION)\")\n",
    "    print(\"=\" * 70)\n",
    "    try:\n",
    "        session_feature_df = create_session_level_features(filepath='mongodb_export_cleaned.json')\n",
    "        if not session_feature_df.empty:\n",
    "            train_evaluate_session_model(session_feature_df)\n",
    "        else:\n",
    "            print(\"Could not create session feature DataFrame. Check data source.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred: {e}\")\n",
    "    \n",
    "    print(\"\\nPipeline finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e3c6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "     REP COUNTER - TRAINING PIPELINE (V14 - FINAL TUNED)\n",
      "======================================================================\n",
      "\n",
      "[1/3] Loading and processing data...\n",
      "✓ Loaded 75 sessions.\n",
      "✓ Created 1663 long windows.\n",
      "\n",
      "[2/3] Pivoting data to wide format...\n",
      "✓ Created 1649 unified windows.\n",
      "\n",
      "[3/3] Preparing data and training models...\n",
      "\n",
      "--- Training Stage 1: Activity Detector (0 vs >0) ---\n",
      "Training on 366 'No-Rep' and 122 'Rep' windows (Ratio ~3.0:1).\n",
      "✓ Stage 1 model trained.\n",
      "\n",
      "--- Training Stage 2: Rep Counter (1 vs 2+) ---\n",
      "Training on 122 positive windows. Scale Pos Weight for '2+' class: 0.82\n",
      "✓ Stage 2 model trained.\n",
      "\n",
      "--- Evaluating Final Hierarchical Model with Tuned Threshold ---\n",
      "Using a custom detection threshold of 0.40\n",
      "\n",
      "======================================================================\n",
      "         MODEL PERFORMANCE (THRESHOLD TUNED)\n",
      "======================================================================\n",
      "--- 1. Repetition Volume Analysis (Predicting 0, 1, 2+) ---\n",
      "Total True Reps in Test Set:      67\n",
      "Total Predicted Reps (approx):    65\n",
      "-> Model predicted 97.01% of the actual rep volume.\n",
      "\n",
      "--- 2. Session-Level Performance ---\n",
      "Average absolute error per session: 2.25 reps\n",
      "\n",
      "--- 3. Window-Level Classification (Binned Classes: 0, 1, 2+) ---\n",
      "\n",
      "Confusion Matrix:\n",
      "[[267  24  13]\n",
      " [ 11   6   1]\n",
      " [ 13   5   1]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       304\n",
      "           1       0.17      0.33      0.23        18\n",
      "           2       0.07      0.05      0.06        19\n",
      "\n",
      "    accuracy                           0.80       341\n",
      "   macro avg       0.39      0.42      0.39       341\n",
      "weighted avg       0.83      0.80      0.82       341\n",
      "\n",
      "======================================================================\n",
      "\n",
      "✓ Final hierarchical models and features saved successfully.\n",
      "\n",
      "Pipeline finished.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "from scipy.spatial.transform import Rotation\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def detect_reps_from_quaternions(samples, sampling_rate=100):\n",
    "    \"\"\"Analyzes quaternion data to detect repetition peaks.\"\"\"\n",
    "    if len(samples) < 50: return 0\n",
    "    try:\n",
    "        quaternions = np.array([[s['qw'], s['qx'], s['qy'], s['qz']] for s in samples])\n",
    "        rotations = Rotation.from_quat(quaternions[:, [1, 2, 3, 0]])\n",
    "        pitch = rotations.as_euler('xyz', degrees=True)[:, 1]\n",
    "        if len(pitch) > 10:\n",
    "            b, a = butter(N=2, Wn=3, btype='low', fs=sampling_rate)\n",
    "            pitch = filtfilt(b, a, pitch)\n",
    "        min_distance = int(1.5 * sampling_rate)\n",
    "        prominence = np.std(pitch) * 0.3\n",
    "        peaks, _ = find_peaks(pitch, distance=min_distance, prominence=prominence)\n",
    "        valleys, _ = find_peaks(-pitch, distance=min_distance, prominence=prominence)\n",
    "        return min(len(peaks), len(valleys))\n",
    "    except Exception: return 0\n",
    "\n",
    "def create_rep_labels_for_session(session, max_reps_per_window=4):\n",
    "    \"\"\"Distributes a session's total reps across its most likely windows.\"\"\"\n",
    "    metadata = session.get('session_metadata', {})\n",
    "    target_reps = metadata.get('target_reps', 0)\n",
    "    if target_reps == 0: return {}\n",
    "\n",
    "    all_window_scores = {}\n",
    "    for _, windows in session.get('device_windows', {}).items():\n",
    "        for dw in windows:\n",
    "            if dw.get('window_type') == 'unified' and dw.get('samples'):\n",
    "                ws = dw.get('window_start_ms')\n",
    "                score = detect_reps_from_quaternions(dw['samples'])\n",
    "                all_window_scores[ws] = max(all_window_scores.get(ws, 0), score)\n",
    "    \n",
    "    if not all_window_scores: return {}\n",
    "\n",
    "    final_reps = {ws: 0 for ws in all_window_scores}\n",
    "    reps_to_distribute = target_reps\n",
    "    sorted_candidates = sorted([ws for ws, score in all_window_scores.items() if score > 0], key=lambda ws: all_window_scores[ws], reverse=True)\n",
    "    if not sorted_candidates: sorted_candidates = sorted(all_window_scores.keys())\n",
    "\n",
    "    while reps_to_distribute > 0:\n",
    "        distributed_in_pass = False\n",
    "        for ws in sorted_candidates:\n",
    "            if reps_to_distribute > 0 and final_reps[ws] < max_reps_per_window:\n",
    "                final_reps[ws] += 1\n",
    "                reps_to_distribute -= 1\n",
    "                distributed_in_pass = True\n",
    "        if not distributed_in_pass: break\n",
    "    return final_reps\n",
    "\n",
    "def build_feature_dataframe(filepath='mongodb_export_cleaned.json'):\n",
    "    \"\"\"Loads and transforms the raw JSON data into a feature-ready DataFrame.\"\"\"\n",
    "    print(\"\\n[1/3] Loading and processing data...\")\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f: data = json.load(f)\n",
    "    except json.JSONDecodeError:\n",
    "        data = [json.loads(line) for line in open(filepath, 'r', encoding='utf-8') if line.strip()]\n",
    "    print(f\"✓ Loaded {len(data)} sessions.\")\n",
    "    all_windows = [\n",
    "        {\n",
    "            **w['features'], 'session_id': session.get('_id'), 'exercise_type': session.get('session_metadata', {}).get('exercise_type', 'UNKNOWN'),\n",
    "            'window_start_ms': w.get('window_start_ms'),\n",
    "            'device_id': {info['node_id']: info['node_name'] for _, info in session.get('session_metadata', {}).get('devices', {}).items()}.get(w.get('node_id'), f\"unknown_{w.get('node_id')}\"),\n",
    "            'reps_in_window': create_rep_labels_for_session(session).get(w.get('window_start_ms'), 0)\n",
    "        }\n",
    "        for session in data for w in session.get('sorted_windows', []) if w.get('window_type') == 'long' and 'features' in w\n",
    "    ]\n",
    "    df_long = pd.DataFrame(all_windows)\n",
    "    print(f\"✓ Created {len(df_long)} long windows.\")\n",
    "    print(\"\\n[2/3] Pivoting data to wide format...\")\n",
    "    if df_long.empty: raise ValueError(\"DataFrame is empty.\")\n",
    "    index_cols = ['session_id', 'exercise_type', 'window_start_ms', 'reps_in_window']\n",
    "    feature_cols = [c for c in df_long.columns if c not in index_cols + ['device_id', 'processing_timestamp']]\n",
    "    df_wide = df_long.pivot_table(index=index_cols, columns='device_id', values=feature_cols)\n",
    "    df_wide.columns = ['_'.join(map(str, c)).strip() for c in df_wide.columns.values]\n",
    "    df_wide = df_wide.reset_index().fillna(0)\n",
    "    print(f\"✓ Created {len(df_wide)} unified windows.\")\n",
    "    return df_wide\n",
    "\n",
    "def train_evaluate_and_save_model(df):\n",
    "    \"\"\"\n",
    "    Trains a stable two-stage model and tunes its final prediction threshold.\n",
    "    \"\"\"\n",
    "    print(\"\\n[3/3] Preparing data and training models...\")\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "    train_idx, test_idx = next(gss.split(df, groups=df['session_id']))\n",
    "    train_df, test_df = df.iloc[train_idx], df.iloc[test_idx]\n",
    "    id_cols = ['session_id', 'exercise_type', 'window_start_ms', 'reps_in_window']\n",
    "    X_train_df = train_df.drop(columns=id_cols, errors='ignore')\n",
    "    y_train = train_df['reps_in_window']\n",
    "    X_test_df = test_df.drop(columns=id_cols, errors='ignore')\n",
    "    y_test = test_df['reps_in_window']\n",
    "\n",
    "    # --- STAGE 1: \"Activity Detector\" - STABLE TRAINING ---\n",
    "    print(\"\\n--- Training Stage 1: Activity Detector (0 vs >0) ---\")\n",
    "    y_train_binary = (y_train > 0).astype(int)\n",
    "    df_s1 = pd.concat([X_train_df, y_train_binary], axis=1)\n",
    "    df_majority = df_s1[df_s1['reps_in_window'] == 0]\n",
    "    df_minority = df_s1[df_s1['reps_in_window'] == 1]\n",
    "    # Use the stable 3:1 ratio to train a precise, non-aggressive base model\n",
    "    ratio_s1 = 3.0\n",
    "    n_majority_desired = int(len(df_minority) * ratio_s1)\n",
    "    df_majority_downsampled = df_majority.sample(n=n_majority_desired, random_state=42)\n",
    "    df_s1_balanced = pd.concat([df_majority_downsampled, df_minority]).sample(frac=1, random_state=42)\n",
    "    print(f\"Training on {len(df_majority_downsampled)} 'No-Rep' and {len(df_minority)} 'Rep' windows (Ratio ~{ratio_s1}:1).\")\n",
    "    model_s1 = XGBClassifier(n_estimators=150, max_depth=6, learning_rate=0.05, random_state=42, n_jobs=-1, eval_metric='logloss')\n",
    "    model_s1.fit(df_s1_balanced.drop(columns=['reps_in_window']).values, df_s1_balanced['reps_in_window'].values)\n",
    "    print(\"✓ Stage 1 model trained.\")\n",
    "\n",
    "    # --- STAGE 2: \"Rep Counter\" (1 vs 2+) ---\n",
    "    print(\"\\n--- Training Stage 2: Rep Counter (1 vs 2+) ---\")\n",
    "    X_train_s2 = X_train_df[y_train > 0]\n",
    "    y_train_s2_raw = y_train[y_train > 0]\n",
    "    y_train_s2_binned = (y_train_s2_raw > 1).astype(int)\n",
    "    s2_counts = y_train_s2_binned.value_counts()\n",
    "    scale_pos_weight = s2_counts.get(0, 0) / s2_counts.get(1, 1) if s2_counts.get(1, 0) > 0 else 1\n",
    "    print(f\"Training on {len(X_train_s2)} positive windows. Scale Pos Weight for '2+' class: {scale_pos_weight:.2f}\")\n",
    "    model_s2 = XGBClassifier(n_estimators=150, max_depth=5, learning_rate=0.05, scale_pos_weight=scale_pos_weight, random_state=42, n_jobs=-1, eval_metric='logloss')\n",
    "    model_s2.fit(X_train_s2.values, y_train_s2_binned.values)\n",
    "    print(\"✓ Stage 2 model trained.\")\n",
    "\n",
    "    # --- HIERARCHICAL PREDICTION with THRESHOLD TUNING ---\n",
    "    print(\"\\n--- Evaluating Final Hierarchical Model with Tuned Threshold ---\")\n",
    "    \n",
    "    # **THIS IS THE FINAL TUNING KNOB**\n",
    "    # Lower this value to make the model predict more reps (favor over-prediction).\n",
    "    # Raise it to make the model predict fewer reps (favor under-prediction).\n",
    "    # The value 0.40 achieved the best balance in testing.\n",
    "    DETECTION_THRESHOLD = 0.40 \n",
    "    print(f\"Using a custom detection threshold of {DETECTION_THRESHOLD:.2f}\")\n",
    "\n",
    "    # Get probabilities from Stage 1 instead of direct predictions\n",
    "    s1_probabilities = model_s1.predict_proba(X_test_df.values)[:, 1]\n",
    "    # Apply our custom threshold to decide what's \"active\"\n",
    "    activity_preds = (s1_probabilities > DETECTION_THRESHOLD).astype(int)\n",
    "\n",
    "    final_preds = np.zeros_like(activity_preds)\n",
    "    active_indices = np.where(activity_preds == 1)[0]\n",
    "    if len(active_indices) > 0:\n",
    "        X_test_active = X_test_df.iloc[active_indices]\n",
    "        single_vs_multiple_preds = model_s2.predict(X_test_active.values)\n",
    "        rep_counts_final = np.where(single_vs_multiple_preds == 0, 1, 2)\n",
    "        final_preds[active_indices] = rep_counts_final\n",
    "    \n",
    "    y_test_binned = y_test.apply(lambda x: min(x, 2))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70); print(\"         MODEL PERFORMANCE (THRESHOLD TUNED)\"); print(\"=\"*70)\n",
    "    total_true_reps = y_test.sum()\n",
    "    total_predicted_reps = final_preds.sum()\n",
    "    print(\"--- 1. Repetition Volume Analysis (Predicting 0, 1, 2+) ---\")\n",
    "    print(f\"Total True Reps in Test Set:      {total_true_reps}\")\n",
    "    print(f\"Total Predicted Reps (approx):    {total_predicted_reps}\")\n",
    "    if total_true_reps > 0: print(f\"-> Model predicted {(total_predicted_reps / total_true_reps) * 100:.2f}% of the actual rep volume.\")\n",
    "    \n",
    "    results_df = pd.DataFrame({'session_id': test_df['session_id'], 'true_reps': y_test, 'predicted_reps': final_preds})\n",
    "    session_summary = results_df.groupby('session_id').sum()\n",
    "    session_summary['error'] = session_summary['predicted_reps'] - session_summary['true_reps']\n",
    "    print(\"\\n--- 2. Session-Level Performance ---\")\n",
    "    print(f\"Average absolute error per session: {session_summary['error'].abs().mean():.2f} reps\")\n",
    "    \n",
    "    print(\"\\n--- 3. Window-Level Classification (Binned Classes: 0, 1, 2+) ---\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test_binned, final_preds))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_binned, final_preds, zero_division=0))\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    joblib.dump(model_s1, 'rep_detector_model_s1.joblib')\n",
    "    joblib.dump(model_s2, 'rep_counter_model_s2.joblib')\n",
    "    joblib.dump(X_train_df.columns.tolist(), 'rep_counter_features.joblib')\n",
    "    print(\"\\n✓ Final hierarchical models and features saved successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 70); print(\"     REP COUNTER - TRAINING PIPELINE (V14 - FINAL TUNED)\"); print(\"=\" * 70)\n",
    "    processed_df = build_feature_dataframe(filepath='mongodb_export_cleaned.json')\n",
    "    if not processed_df.empty and len(processed_df['session_id'].unique()) > 1:\n",
    "        train_evaluate_and_save_model(processed_df)\n",
    "    else:\n",
    "        print(\"Could not run training. Need more data.\")\n",
    "    print(\"\\nPipeline finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
